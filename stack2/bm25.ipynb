{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from matplotlib_venn import venn2, venn2_circles\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import scipy\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import KFold\n",
    "import time\n",
    "\n",
    "NFOLDS = 5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Feature engineering\n",
      "Processing text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "\n",
    "def bm25(corpus,b,k1, stopword):\n",
    "    CV = CountVectorizer(ngram_range=(1,1), stop_words = stopword, min_df=5,max_df=0.3)\n",
    "    IDFTrans = TfidfTransformer(norm='l2')\n",
    "    \n",
    "    output = CV.fit_transform(corpus)\n",
    "    IDFTrans.fit(output)\n",
    "    feature_names = CV.get_feature_names()\n",
    "    temp = output.copy()\n",
    "    \n",
    "    aveL = output.sum()/output.shape[0]\n",
    "    denominator = k1 * ((1-b)+b*(output.sum(1)/aveL))\n",
    "    \n",
    "    temp.data = temp.data/temp.data\n",
    "    temp = csr_matrix.multiply(temp,denominator)\n",
    "    \n",
    "    temp += output\n",
    "    output *= (k1+1)\n",
    "\n",
    "    temp.data = 1/temp.data\n",
    "    output = csr_matrix.multiply(output,temp)\n",
    "    \n",
    "    output = IDFTrans.transform(output)\n",
    "    \n",
    "    return output, feature_names\n",
    "\t\n",
    "def cleanName(text):\n",
    "    try:\n",
    "        textProc = text.lower()\n",
    "        textProc = re.sub('[!@#$_“”¨«»®´·º½¾¿¡§£₤‘’]', '', textProc)\n",
    "        textProc = \" \".join(textProc.split())\n",
    "        return textProc\n",
    "    except: \n",
    "        return \"name error\"\n",
    "\t\t\n",
    "\n",
    "sw = stopwords.words('russian')\n",
    "\n",
    "print(\"Loading data\")\n",
    "train =pd.read_csv(\"/home/g492652607/data/train.csv\") \n",
    "test =pd.read_csv(\"/home/g492652607/data/test.csv\")\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "categorical = [\"user_id\",\"city\",\"parent_category_name\",\"user_type\",\"region\",\"category_name\"] # labelencoding\n",
    "nullP = [\"image_top_1\",\"param_1\",\"param_2\",\"param_3\"] # labelencoding with NA (add an indicator to identify whether it is NA)\n",
    "isNA = [] # indicator of NA\n",
    "dropOr = [\"item_id\",\"title\",\"description\"] # to drop\n",
    "\n",
    "trainIndex=train.shape[0]\n",
    "train_y = train.deal_probability\n",
    "train_x = train.drop(columns=\"deal_probability\")\n",
    "\n",
    "tr_te = pd.concat([train_x,test],axis=0)\n",
    "\n",
    "print(\"Feature engineering\")\n",
    "tr_te = tr_te.assign(mon=lambda x: pd.to_datetime(x['activation_date']).dt.month,\n",
    "                     mday=lambda x: pd.to_datetime(x['activation_date']).dt.day,\n",
    "                     week=lambda x: pd.to_datetime(x['activation_date']).dt.week,\n",
    "                     wday=lambda x:pd.to_datetime(x['activation_date']).dt.dayofweek,\n",
    "                     txt=lambda x:(x['title'].astype(str)+' '+x['description'].astype(str)))\n",
    "\n",
    "del train, test, train_x\n",
    "gc.collect()\n",
    "\n",
    "tr_te[\"price\"] = np.log(tr_te[\"price\"]+0.001)\n",
    "tr_te[\"price\"].fillna(tr_te.price.mean(),inplace=True)\n",
    "\n",
    "tr_te.drop([\"activation_date\",\"image\"],axis=1,inplace=True)\n",
    "\n",
    "# labelencoding with NA\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in nullP:\n",
    "    toApp = tr_te[col].isnull()\n",
    "    tr_te[col].fillna(\"Unknown\",inplace = True)\n",
    "    tr_te[col] = lbl.fit_transform(tr_te[col].astype(str))\n",
    "    toApp *= 1\n",
    "    theName = \"isNA_\" + col\n",
    "    isNA.append(theName)\n",
    "    tr_te = pd.concat([tr_te,toApp.rename(theName)],axis=1)\n",
    "\n",
    "# labelencoding\n",
    "for col in categorical:\n",
    "    tr_te[col].fillna('Unknown')\n",
    "    tr_te[col] = lbl.fit_transform(tr_te[col].astype(str))\n",
    "\t\n",
    "tr_te.drop(labels=dropOr,axis=1,inplace=True)\n",
    "\n",
    "tr_te.loc[:,'txt']=tr_te.txt.apply(lambda x:x.lower().replace(\"[^[:alpha:]]\",\" \").replace(\"\\\\s+\", \" \"))\n",
    "tr_te['txt'] = tr_te['txt'].apply(lambda x: cleanName(x))\n",
    "\n",
    "print(\"Processing text\")\n",
    "\n",
    "m_tfidf, tfidf_feature = bm25(tr_te.txt,0.75,2,stopword=sw)\n",
    "\n",
    "tr_te.drop(labels=['txt'],inplace=True,axis=1)\n",
    "\n",
    "feature_list = tr_te.columns.values.tolist()\n",
    "feature_list.extend(tfidf_feature)\n",
    "categorical.extend(nullP)\n",
    "categorical.extend(isNA)\n",
    "\n",
    "data  = hstack((tr_te.values,m_tfidf)).tocsr()\n",
    "\n",
    "del tr_te,m_tfidf\n",
    "gc.collect()\n",
    "\n",
    "dtest = data[trainIndex:]\n",
    "train = data[:trainIndex]\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_lgb(params, x_train, y_train, x_test, kf, cat_cols=[],\n",
    "                       verbose=True, verbose_eval=50, use_cat=True, use_rank=False):\n",
    "    start_time = time.time()\n",
    "    train_pred = np.zeros((ntrain))\n",
    "    test_pred = np.zeros((ntest))\n",
    "\n",
    "    if len(cat_cols)==0: use_cat=False\n",
    "\n",
    "    # use the k-fold object to enumerate indexes for each training and validation fold\n",
    "    for i, (train_index, val_index) in enumerate(kf): # folds 1, 2 ,3 ,4, 5\n",
    "        # example: training from 1,2,3,4; validation from 5\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "        y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        if use_cat:\n",
    "            lgb_train = lgb.Dataset(x_train_kf, y_train_kf, feature_name=feature_list,categorical_feature=cat_cols)\n",
    "            lgb_val = lgb.Dataset(x_val_kf, y_val_kf, reference=lgb_train, feature_name=feature_list,categorical_feature=cat_cols)\n",
    "        else:\n",
    "            lgb_train = lgb.Dataset(x_train_kf, y_train_kf, feature_name=feature_list)\n",
    "            lgb_val = lgb.Dataset(x_val_kf, y_val_kf, reference=lgb_train, feature_name=feature_list)\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=4000,\n",
    "                        valid_sets=lgb_val,\n",
    "                        early_stopping_rounds=30,\n",
    "                        verbose_eval=verbose_eval)\n",
    "\n",
    "        val_pred = gbm.predict(x_val_kf)\n",
    "\n",
    "        if use_rank:\n",
    "            train_pred[val_index] += probability_to_rank(val_pred)\n",
    "            test_pred += probability_to_rank(gbm.predict(x_test))\n",
    "            # test_pred += gbm.predict(x_test)\n",
    "        else:\n",
    "            train_pred[val_index] += val_pred\n",
    "            test_pred += gbm.predict(x_test)\n",
    "\n",
    "        # test_pred += gbm.predict(x_test)\n",
    "        rms = sqrt(mean_squared_error(y_val_kf.values, val_pred))\n",
    "        if verbose:\n",
    "            print('fold cv {} RMSE score is {:.6f}'.format(i, rms))\n",
    "\n",
    "    test_pred /=NFOLDS\n",
    "\n",
    "    cv_rms = sqrt(mean_squared_error(y_train, train_pred))\n",
    "    if verbose:\n",
    "        print('cv RMSE score is {:.6f}'.format(cv_rms))\n",
    "        end_time = time.time()\n",
    "        print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n",
    "    return train_pred.reshape(-1, 1),test_pred.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g492652607/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/g492652607/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold cv 0 RMSE score is 0.218641\n",
      "\n",
      "Fold 1\n",
      "fold cv 1 RMSE score is 0.218914\n",
      "\n",
      "Fold 2\n",
      "fold cv 2 RMSE score is 0.218556\n",
      "\n",
      "Fold 3\n",
      "fold cv 3 RMSE score is 0.218676\n",
      "\n",
      "Fold 4\n",
      "fold cv 4 RMSE score is 0.218772\n",
      "cv RMSE score is 0.218712\n",
      "it takes 20275.585 seconds to perform cross validation\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(ntrain, n_folds=NFOLDS, random_state=SEED)\n",
    "lgb_params =  {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 270,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'learning_rate': 0.016,\n",
    "    'verbose': 0\n",
    "}  \n",
    "gbm_oof_train, gbm_oof_test=cross_validate_lgb(lgb_params,train, train_y, dtest, kf, cat_cols=categorical, use_cat=True, \n",
    "                            verbose_eval=False, use_rank=False)\n",
    "\n",
    "\n",
    "gbm_preds = np.concatenate([gbm_oof_train, gbm_oof_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv('/home/g492652607/data/sample_submission.csv')\n",
    "subm['deal_probability'] = np.clip(gbm_oof_test, 0, 1)\n",
    "subm.to_csv('testbm25.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = pd.read_csv('/home/g492652607/data/blend.csv') \n",
    "idx=blend['item_id']\n",
    "sub = pd.DataFrame(gbm_preds,columns=['gbm_pred'])\n",
    "sub1 = pd.DataFrame(idx,columns=['item_id'])\n",
    "sub1=sub1.set_index(sub.index)\n",
    "gb=pd.concat([sub1,sub],axis=1)\n",
    "gb.to_csv('gbm_bm25.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.to_csv('bm25.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2011862, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
