{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79cde592-cafb-467a-9e13-13297afede14",
    "_uuid": "208338288dcff3afa0867b306720403185a0f482"
   },
   "source": [
    "### This kernel is forked from https://www.kaggle.com/bminixhofer/aggregated-features-lightgbm . I have done some changes to get better score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "033852ed-2dd3-4bc3-bec1-ac3481ab175f",
    "_kg_hide-input": true,
    "_uuid": "af7422df064b7f16934cca9e86e8213bc9c667e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g492652607/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from matplotlib_venn import venn2, venn2_circles\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import scipy\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import KFold\n",
    "import time\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "NFOLDS = 5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "94a03718-1718-4981-88ef-532efcb435ee",
    "_uuid": "5d8e0a1a86fe5fbfa5162d3180d0b1ebea94f97d"
   },
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "bc719fcf-f418-4db5-a4fa-ebfa27716521",
    "_uuid": "02aad0b977053435e089bd189ea45e4a88731e87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>deal_probability</th>\n",
       "      <th>avg_days_up_user</th>\n",
       "      <th>avg_times_up_user</th>\n",
       "      <th>n_user_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>Свердловская область</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>Private</td>\n",
       "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0.12789</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>Самарская область</td>\n",
       "      <td>Самара</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>Private</td>\n",
       "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>91e2f88dd6e3</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>Private</td>\n",
       "      <td>b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>0.43177</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>bf5cccea572d</td>\n",
       "      <td>Татарстан</td>\n",
       "      <td>Набережные Челны</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>...</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>286</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>Company</td>\n",
       "      <td>e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...</td>\n",
       "      <td>796.0</td>\n",
       "      <td>0.80323</td>\n",
       "      <td>16.714286</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>ef50846afc0b</td>\n",
       "      <td>Волгоградская область</td>\n",
       "      <td>Волгоград</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>...</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>Private</td>\n",
       "      <td>54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.20797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id                 region              city  \\\n",
       "0  b912c3c6a6ad  e00f8ff2eaf9   Свердловская область      Екатеринбург   \n",
       "1  2dac0150717d  39aeb48f0017      Самарская область            Самара   \n",
       "2  ba83aefab5dc  91e2f88dd6e3     Ростовская область    Ростов-на-Дону   \n",
       "3  02996f1dd2ea  bf5cccea572d              Татарстан  Набережные Челны   \n",
       "4  7c90be56d2ab  ef50846afc0b  Волгоградская область         Волгоград   \n",
       "\n",
       "  parent_category_name               category_name  \\\n",
       "0          Личные вещи  Товары для детей и игрушки   \n",
       "1      Для дома и дачи           Мебель и интерьер   \n",
       "2  Бытовая электроника               Аудио и видео   \n",
       "3          Личные вещи  Товары для детей и игрушки   \n",
       "4            Транспорт                  Автомобили   \n",
       "\n",
       "                       param_1     param_2 param_3                  title  \\\n",
       "0    Постельные принадлежности         NaN     NaN  Кокоби(кокон для сна)   \n",
       "1                       Другое         NaN     NaN      Стойка для Одежды   \n",
       "2  Видео, DVD и Blu-ray плееры         NaN     NaN         Philips bluray   \n",
       "3         Автомобильные кресла         NaN     NaN             Автокресло   \n",
       "4                   С пробегом  ВАЗ (LADA)    2110         ВАЗ 2110, 2003   \n",
       "\n",
       "       ...         price  item_seq_number  activation_date user_type  \\\n",
       "0      ...         400.0                2       2017-03-28   Private   \n",
       "1      ...        3000.0               19       2017-03-26   Private   \n",
       "2      ...        4000.0                9       2017-03-20   Private   \n",
       "3      ...        2200.0              286       2017-03-25   Company   \n",
       "4      ...       40000.0                3       2017-03-16   Private   \n",
       "\n",
       "                                               image image_top_1  \\\n",
       "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...      1008.0   \n",
       "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...       692.0   \n",
       "2  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...      3032.0   \n",
       "3  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...       796.0   \n",
       "4  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...      2264.0   \n",
       "\n",
       "   deal_probability  avg_days_up_user  avg_times_up_user  n_user_items  \n",
       "0           0.12789          8.000000           2.000000             2  \n",
       "1           0.00000               NaN                NaN             1  \n",
       "2           0.43177          4.428571           1.142857             9  \n",
       "3           0.80323         16.714286           2.642857            32  \n",
       "4           0.20797               NaN                NaN             1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/home/g492652607/data/train.csv')\n",
    "test = pd.read_csv('/home/g492652607/data/test.csv')\n",
    "gp = pd.read_csv('/home/g492652607/data/aggregated_features.csv') \n",
    "train = train.merge(gp, on='user_id', how='left')\n",
    "test = test.merge(gp, on='user_id', how='left')\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "agg_cols = list(gp.columns)[1:]\n",
    "\n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78cc3f11-d2c4-4ed8-a7b8-ba44f884c3d6",
    "_uuid": "be70118249f82d7e85cf7ee525303bc4d580932e"
   },
   "source": [
    "# Feature Engineering\n",
    "### Text cleaning does not help So, I am commenting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "acde3dd7751d09b6114d000a4aab2835a8d74aef"
   },
   "outputs": [],
   "source": [
    "blend = pd.read_csv('/home/g492652607/data/blend.csv') \n",
    "train=train.merge(blend, on='item_id', how='left')\n",
    "test=test.merge(blend, on='item_id', how='left')\n",
    "idx=blend['item_id']\n",
    "\n",
    "img_t=pd.read_csv('/home/g492652607/data/test_0.csv')\n",
    "img0=pd.read_csv('/home/g492652607/data/train-0.csv')\n",
    "img1=pd.read_csv('/home/g492652607/data/train-1.csv')\n",
    "img2=pd.read_csv('/home/g492652607/data/train-2.csv')\n",
    "img4=pd.read_csv('/home/g492652607/data/train-4.csv')\n",
    "img3=pd.read_csv('/home/g492652607/data/train-3.csv')\n",
    "img=pd.concat([img_t,img0,img1,img2,img3,img4],axis=0)\n",
    "img['image']=list(img['image'].str.split('.').str[0])\n",
    "train=train.merge(img, on='image', how='left')\n",
    "test=test.merge(img, on='image', how='left')\n",
    "\n",
    "img.drop('image',axis=1,inplace=True)\n",
    "img_col=list(img.columns)\n",
    "\n",
    "vgg1 = pd.read_csv('/home/g492652607/data/VGG16_1.csv')\n",
    "vgg2 = pd.read_csv('/home/g492652607/data/VGG16_2.csv')\n",
    "vgg3 = pd.read_csv('/home/g492652607/data/VGG16_3.csv')\n",
    "vgg=pd.merge(vgg1,vgg2,on='item_id',how='left')\n",
    "vgg=vgg.merge(vgg3,on='item_id',how='left')\n",
    "train=train.merge(vgg, on='item_id', how='left')\n",
    "test=test.merge(vgg, on='item_id', how='left')\n",
    "vgg.drop('item_id',axis=1,inplace=True)\n",
    "img_col2=list(vgg.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7fd4c131319264c5ad95655e19c0a42aa5c27782",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_id', 'user_id', 'region', 'city', 'parent_category_name',\n",
      "       'category_name', 'param_1', 'param_2', 'param_3', 'title',\n",
      "       'description', 'price', 'item_seq_number', 'activation_date',\n",
      "       'user_type', 'image', 'image_top_1', 'deal_probability',\n",
      "       'avg_days_up_user', 'avg_times_up_user', 'n_user_items', 'rnn_pred',\n",
      "       't', 'd', 'ridge_pred', 'cb_pred', 'user_price_aver', 'user_price_std',\n",
      "       'user_seq_aver', 'user_seq_std',\n",
      "       'user_id_parent_category_name_category_name_count',\n",
      "       'user_id_parent_category_name_category_name_aver_pri',\n",
      "       'region_city_parent_category_name_category_name_count', 'dullness',\n",
      "       'whiteness', 'average_pixel_width', 'dominant_red', 'dominant_green',\n",
      "       'dominant_blue', 'average_red', 'average_green', 'average_blue',\n",
      "       'image_size', 'width', 'height', 'blurrness', 'im_tsvd_0', 'im_tsvd_1',\n",
      "       'im_tsvd_2', 'im_tsvd_3', 'im_tsvd_4', 'im_tsvd_5', 'im_tsvd_6',\n",
      "       'im_tsvd_7', 'im_tsvd_8', 'im_tsvd_9', 'im_tsvd_10', 'im_tsvd_11',\n",
      "       'im_tsvd_12', 'im_tsvd_13', 'im_tsvd_14', 'im_tsvd_15', 'im_tsvd_16',\n",
      "       'im_tsvd_17', 'im_tsvd_18', 'im_tsvd_19', 'im_tsvd_20', 'im_tsvd_21',\n",
      "       'im_tsvd_22', 'im_tsvd_23', 'im_tsvd_24', 'im_tsvd_25', 'im_tsvd_26',\n",
      "       'im_tsvd_27', 'im_tsvd_28', 'im_tsvd_29', 'im_tsvd_30', 'im_tsvd_31',\n",
      "       'im_max_feature', 'im_min_feature', 'im_n_features', 'im_mean_features',\n",
      "       'im_meansquare_features'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "41e1111d-674e-4c86-b232-c0086832ee6d",
    "_uuid": "9c60409e1dc6c618f229e15c2b368660385c2ec1"
   },
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df['description'].fillna('unknowndesc', inplace=True)\n",
    "    df['title'].fillna('unknowntitle', inplace=True)\n",
    "\n",
    "    df['weekday'] = pd.to_datetime(df['activation_date']).dt.weekday\n",
    " #   df['dayofmonth'] = pd.to_datetime(df['activation_date']).dt.day\n",
    "    \n",
    "    for col in ['description', 'title']:\n",
    "        df['num_words_' + col] = df[col].apply(lambda comment: len(comment.split()))\n",
    "        df['num_unique_words_' + col] = df[col].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "\n",
    "    df['words_vs_unique_title'] = df['num_unique_words_title'] / df['num_words_title'] * 100\n",
    "    df['words_vs_unique_description'] = df['num_unique_words_description'] / df['num_words_description'] * 100\n",
    "    \n",
    "    df['city'] = df['region'] + '_' + df['city']\n",
    "    df['num_desc_punct'] = df['description'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "    \n",
    "    for col in agg_cols:\n",
    "        df[col].fillna(-1, inplace=True)\n",
    "        \n",
    "    for col in img_col:\n",
    "        df[col].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8d61ada6-8f3a-4b58-baad-199589122985",
    "_uuid": "cc558a03cbddc3954b01783636785cdee6cf954a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1503424, 5000), (1503424, 5000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer_title = CountVectorizer(stop_words=stopwords.words('russian'), lowercase=True, min_df=2,max_features=5000)\n",
    "\n",
    "title_counts = count_vectorizer_title.fit_transform(train['title'].append(test['title']))\n",
    "\n",
    "train_title_counts = title_counts[:len(train)]\n",
    "test_title_counts = title_counts[len(train):]\n",
    "\n",
    "\n",
    "count_vectorizer_desc = TfidfVectorizer(stop_words=stopwords.words('russian'), \n",
    "                                        lowercase=True, ngram_range=(1, 2),\n",
    "                                        max_features=5000)\n",
    "\n",
    "desc_counts = count_vectorizer_desc.fit_transform(train['description'].append(test['description']))\n",
    "\n",
    "train_desc_counts = desc_counts[:len(train)]\n",
    "test_desc_counts = desc_counts[len(train):]\n",
    "\n",
    "train_title_counts.shape, train_desc_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "56338e56-c266-4342-a8f3-10621db49dee",
    "_uuid": "cc6f15f981f05ad9b1e89ab7acb54ea2350278c6"
   },
   "outputs": [],
   "source": [
    "target = 'deal_probability'\n",
    "predictors = [\n",
    "    'num_desc_punct',\n",
    "    'words_vs_unique_description', 'num_unique_words_description', 'num_unique_words_title', 'num_words_description', 'num_words_title',\n",
    "    'avg_times_up_user', 'avg_days_up_user', 'n_user_items', \n",
    "    'price', 'item_seq_number', 'user_price_aver', 'user_price_std', 'user_seq_aver', 'user_seq_std',\n",
    "    'user_id_parent_category_name_category_name_count', \n",
    "    'user_id_parent_category_name_category_name_aver_pri',\n",
    "    'region_city_parent_category_name_category_name_count','rnn_pred','t','d','ridge_pred','cb_pred'\n",
    "]\n",
    "categorical = [\n",
    "    'image_top_1', 'param_1', 'param_2', 'param_3', \n",
    "    'city', 'region', 'category_name', 'parent_category_name', 'user_type'\n",
    "]\n",
    "\n",
    "predictors = predictors + categorical+img_col+img_col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "7695c1a1-06cf-40e6-8792-77b62f48262a",
    "_uuid": "0bcde9bb9b9b26347c7db7da47123c6fec40860e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming image_top_1...\n",
      "Transforming param_1...\n",
      "Transforming param_2...\n",
      "Transforming param_3...\n",
      "Transforming city...\n",
      "Transforming region...\n",
      "Transforming category_name...\n",
      "Transforming parent_category_name...\n",
      "Transforming user_type...\n"
     ]
    }
   ],
   "source": [
    "for feature in categorical:\n",
    "    print(f'Transforming {feature}...')\n",
    "    encoder = LabelEncoder()\n",
    "    train[feature].fillna('unknown',inplace=True)\n",
    "    test[feature].fillna('unknown',inplace=True)\n",
    "    encoder.fit(train[feature].append(test[feature]).astype(str))\n",
    "    \n",
    "    train[feature] = encoder.transform(train[feature].astype(str))\n",
    "    test[feature] = encoder.transform(test[feature].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "0e3cd2be-1a46-4f66-8f7c-9fbb95511b62",
    "_uuid": "26dc041ad0496392176d06882673d130e5219b63",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[\"price\"] = np.log(train[\"price\"]+0.001)\n",
    "train[\"price\"].fillna(-999,inplace=True)\n",
    "train[\"image_top_1\"].fillna(-999,inplace=True)\n",
    "\n",
    "test[\"price\"] = np.log(test[\"price\"]+0.001)\n",
    "test[\"price\"].fillna(-999,inplace=True)\n",
    "test[\"image_top_1\"].fillna(-999,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee4b0666-f0be-4965-9dd9-6651d5c49b2b",
    "_uuid": "dc7dbed2a9943fa245d860de412cdef0e17a49d9"
   },
   "source": [
    "# LightGBM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10082\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.hstack([\n",
    "    count_vectorizer_desc.get_feature_names(),\n",
    "    count_vectorizer_title.get_feature_names(),\n",
    "    predictors\n",
    "])\n",
    "print('Number of features:', len(feature_names))\n",
    "\n",
    "x_test = scipy.sparse.hstack([\n",
    "    test_desc_counts,\n",
    "    test_title_counts,\n",
    "    test.loc[:, predictors]\n",
    "], format='csr')\n",
    "\n",
    "X = scipy.sparse.hstack([\n",
    "    train_desc_counts,\n",
    "    train_title_counts,\n",
    "    train.loc[: , predictors]\n",
    "], format='csr')\n",
    "y = train.deal_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_lgb(params, x_train, y_train, x_test, kf, cat_cols=[],\n",
    "                       verbose=True, verbose_eval=50, use_cat=True, use_rank=False):\n",
    "    start_time = time.time()\n",
    "    train_pred = np.zeros((ntrain))\n",
    "    test_pred = np.zeros((ntest))\n",
    "\n",
    "    if len(cat_cols)==0: use_cat=False\n",
    "\n",
    "    # use the k-fold object to enumerate indexes for each training and validation fold\n",
    "    for i, (train_index, val_index) in enumerate(kf): # folds 1, 2 ,3 ,4, 5\n",
    "        # example: training from 1,2,3,4; validation from 5\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "        y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        if use_cat:\n",
    "            lgb_train = lgb.Dataset(x_train_kf, y_train_kf, feature_name=list(feature_names),categorical_feature=cat_cols)\n",
    "            lgb_val = lgb.Dataset(x_val_kf, y_val_kf, reference=lgb_train, feature_name=list(feature_names),categorical_feature=cat_cols)\n",
    "        else:\n",
    "            lgb_train = lgb.Dataset(x_train_kf, y_train_kf, feature_name=list(feature_names))\n",
    "            lgb_val = lgb.Dataset(x_val_kf, y_val_kf, reference=lgb_train, feature_name=list(feature_names))\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=4000,\n",
    "                        valid_sets=lgb_val,\n",
    "                        early_stopping_rounds=30,\n",
    "                        verbose_eval=verbose_eval)\n",
    "\n",
    "        val_pred = gbm.predict(x_val_kf)\n",
    "\n",
    "        if use_rank:\n",
    "            train_pred[val_index] += probability_to_rank(val_pred)\n",
    "            test_pred += probability_to_rank(gbm.predict(x_test))\n",
    "            # test_pred += gbm.predict(x_test)\n",
    "        else:\n",
    "            train_pred[val_index] += val_pred\n",
    "            test_pred += gbm.predict(x_test)\n",
    "\n",
    "        # test_pred += gbm.predict(x_test)\n",
    "        rms = sqrt(mean_squared_error(y_val_kf.values, val_pred))\n",
    "        if verbose:\n",
    "            print('fold cv {} RMSE score is {:.6f}'.format(i, rms))\n",
    "\n",
    "    test_pred /=NFOLDS\n",
    "\n",
    "    cv_rms = sqrt(mean_squared_error(y_train, train_pred))\n",
    "    if verbose:\n",
    "        print('cv RMSE score is {:.6f}'.format(cv_rms))\n",
    "        end_time = time.time()\n",
    "        print(\"it takes %.3f seconds to perform cross validation\" % (end_time - start_time))\n",
    "    return train_pred.reshape(-1, 1),test_pred.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g492652607/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(ntrain, n_folds=NFOLDS, random_state=SEED)\n",
    "lgb_params = {'learning_rate':0.02,\n",
    "              'task':'train',\n",
    "              'boosting_type':'gbdt',\n",
    "              'metric':'rmse',\n",
    "              'objective':'regression',\n",
    "              'num_leaves':1000,\n",
    "              'max_depth':18,\n",
    "              'min_data_in_leaf':25, #Defaut 20\n",
    "              'feature_fraction': 0.43,\n",
    "              'feature_fraction_seed':0,\n",
    "              'bagging_fraction': 0.46,\n",
    "              #'bagging_freq': 2,\n",
    "              'bagging_seed':0,\n",
    "              'verbose':0,\n",
    "              'num_threads':4 #Put to 4 if you are leaving computer\n",
    "              }\n",
    "gbm_oof_train, gbm_oof_test=cross_validate_lgb(lgb_params,X, y, x_test, kf, cat_cols=categorical, use_cat=True, \n",
    "                            verbose_eval=False, use_rank=False)\n",
    "\n",
    "\n",
    "gbm_preds = np.concatenate([gbm_oof_train, gbm_oof_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40987939],\n",
       "       [0.14368834],\n",
       "       [0.1128581 ],\n",
       "       ...,\n",
       "       [0.06808092],\n",
       "       [0.40200041],\n",
       "       [0.08980047]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(gbm_preds,columns=['gbm4_pred'])\n",
    "sub1 = pd.DataFrame(idx,columns=['item_id'])\n",
    "sub1=sub1.set_index(sub.index)\n",
    "gb=pd.concat([sub1,sub],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.to_csv('gbm1000tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv('/home/g492652607/data/sample_submission.csv')\n",
    "subm['deal_probability'] = np.clip(gbm_oof_test, 0, 1)\n",
    "subm.to_csv('lgbtest1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
