{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time \n",
    "import gc \n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, BatchNormalization, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "import threading\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from contextlib import closing\n",
    "cores = 4\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "### rmse loss for keras\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(\"Filling Missing Values.....\")\n",
    "    \n",
    "    dataset['price'] = dataset['price'].fillna(0).astype('float32')\n",
    "    dataset['param_1'].fillna(value='missing', inplace=True)\n",
    "    dataset['param_2'].fillna(value='missing', inplace=True)\n",
    "    dataset['param_3'].fillna(value='missing', inplace=True)\n",
    "    \n",
    "    dataset['param_1'] = dataset['param_1'].astype(str)\n",
    "    dataset['param_2'] = dataset['param_2'].astype(str)\n",
    "    dataset['param_3'] = dataset['param_3'].astype(str)\n",
    "    \n",
    "    print(\"Casting data types to type Category.......\")\n",
    "    dataset['category_name'] = dataset['category_name'].astype('category')\n",
    "    dataset['parent_category_name'] = dataset['parent_category_name'].astype('category')\n",
    "    dataset['region'] = dataset['region'].astype('category')\n",
    "    dataset['city'] = dataset['city'].astype('category')\n",
    "    \n",
    "    dataset['image_top_1'] = dataset['image_top_1'].fillna('missing')\n",
    "    dataset['image_code'] = dataset['image_top_1'].astype('str')\n",
    "    del dataset['image_top_1']\n",
    "    gc.collect()\n",
    "\n",
    "    #dataset['week'] = pd.to_datetime(dataset['activation_date']).dt.week.astype('uint8')\n",
    "    #dataset['day'] = pd.to_datetime(dataset['activation_date']).dt.day.astype('uint8')\n",
    "    #dataset['wday'] = pd.to_datetime(dataset['activation_date']).dt.dayofweek.astype('uint8')\n",
    "    del dataset['activation_date']\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"Creating New Feature.....\")\n",
    "    dataset['param123'] = (dataset['param_1']+'_'+dataset['param_2']+'_'+dataset['param_3']).astype(str)\n",
    "    del dataset['param_2'], dataset['param_3']\n",
    "    gc.collect()\n",
    "        \n",
    "    print(\"PreProcessing Function completed.\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def keras_fit(train):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    train['title_description']= (train['title']+\" \"+train['description']).astype(str)\n",
    "    del train['description'], train['title']\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"Start Tokenization.....\")\n",
    "    tokenizer = text.Tokenizer(num_words = max_words_title_description)\n",
    "    all_text = np.hstack([train['title_description'].str.lower()])\n",
    "    tokenizer.fit_on_texts(all_text)\n",
    "    del all_text\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"Loading Test for Label Encoding on Train + Test\")\n",
    "    use_cols_test = ['region', 'city', 'parent_category_name', 'category_name', 'param_1', 'param_2', 'param_3', 'image_top_1', 'activation_date']\n",
    "    test = pd.read_csv(\"/home/g492652607/data/test.csv\", usecols = use_cols_test)\n",
    "    \n",
    "    test['image_top_1'] = test['image_top_1'].fillna('missing')\n",
    "    test['image_code'] = test['image_top_1'].astype('str')\n",
    "    del test['image_top_1']\n",
    "    gc.collect()\n",
    "    \n",
    "    #test['week'] = pd.to_datetime(test['activation_date']).dt.week.astype('uint8')\n",
    "    #test['day'] = pd.to_datetime(test['activation_date']).dt.day.astype('uint8')\n",
    "    #test['wday'] = pd.to_datetime(test['activation_date']).dt.dayofweek.astype('uint8')\n",
    "    del test['activation_date']\n",
    "    gc.collect()\n",
    "    \n",
    "    test['param_1'].fillna(value='missing', inplace=True)\n",
    "    test['param_1'] = test['param_1'].astype(str)\n",
    "    test['param_2'].fillna(value='missing', inplace=True)\n",
    "    test['param_2'] = test['param_2'].astype(str)\n",
    "    test['param_3'].fillna(value='missing', inplace=True)\n",
    "    test['param_3'] = test['param_3'].astype(str)\n",
    "\n",
    "    print(\"Creating New Feature.....\")\n",
    "    test['param123'] = (test['param_1']+'_'+test['param_2']+'_'+test['param_3']).astype(str)\n",
    "    del test['param_2'], test['param_3']\n",
    "    gc.collect()\n",
    "    \n",
    "    ntrain = train.shape[0]\n",
    "    DF = pd.concat([train, test], axis = 0)\n",
    "    del train, test\n",
    "    gc.collect()\n",
    "    print(DF.shape)\n",
    "    \n",
    "    print(\"Start Label Encoding process....\")\n",
    "    le_region = LabelEncoder()\n",
    "    le_region.fit(DF.region)\n",
    "    \n",
    "    le_city = LabelEncoder()\n",
    "    le_city.fit(DF.city)\n",
    "    \n",
    "    le_category_name = LabelEncoder()\n",
    "    le_category_name.fit(DF.category_name)\n",
    "    \n",
    "    le_parent_category_name = LabelEncoder()\n",
    "    le_parent_category_name.fit(DF.parent_category_name)\n",
    "    \n",
    "    le_param_1 = LabelEncoder()\n",
    "    le_param_1.fit(DF.param_1)\n",
    "    \n",
    "    le_param123 = LabelEncoder()\n",
    "    le_param123.fit(DF.param123)\n",
    "    \n",
    "    le_image_code = LabelEncoder()\n",
    "    le_image_code.fit(DF.image_code)\n",
    "    \n",
    "    #le_week = LabelEncoder()\n",
    "    #le_week.fit(DF.week)\n",
    "    #le_day = LabelEncoder()\n",
    "    #le_day.fit(DF.day)\n",
    "    #le_wday = LabelEncoder()\n",
    "    #le_wday.fit(DF.wday)\n",
    "    \n",
    "    train = DF[0:ntrain]\n",
    "    del DF \n",
    "    gc.collect()\n",
    "    \n",
    "    train['price'] = np.log1p(train['price'])\n",
    "    train['avg_days_up_user'] = np.log1p(train['avg_days_up_user'])\n",
    "    train['avg_times_up_user'] = np.log1p(train['avg_times_up_user'])\n",
    "    train['n_user_items'] = np.log1p(train['n_user_items'])\n",
    "    train['item_seq_number'] = np.log(train['item_seq_number'])\n",
    "    print(\"Fit on Train Function completed.\")\n",
    "    \n",
    "    return train, tokenizer, le_region, le_city, le_category_name, le_parent_category_name, le_param_1, le_param123, le_image_code\n",
    "\n",
    "def keras_train_transform(dataset):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    dataset['seq_title_description']= tokenizer.texts_to_sequences(dataset.title_description.str.lower())\n",
    "    print(\"Transform done for test\")\n",
    "    print(\"Time taken for Sequence Tokens is\"+str(time.time()-t1))\n",
    "    del train['title_description']\n",
    "    gc.collect()\n",
    "\n",
    "    dataset['region'] = le_region.transform(dataset['region'])\n",
    "    dataset['city'] = le_city.transform(dataset['city'])\n",
    "    dataset['category_name'] = le_category_name.transform(dataset['category_name'])\n",
    "    dataset['parent_category_name'] = le_parent_category_name.transform(dataset['parent_category_name'])\n",
    "    dataset['param_1'] = le_param_1.transform(dataset['param_1'])\n",
    "    dataset['param123'] = le_param123.transform(dataset['param123'])\n",
    "    #dataset['day'] = le_day.transform(dataset['day'])\n",
    "    #dataset['week'] = le_week.transform(dataset['week'])\n",
    "    #dataset['wday'] = le_wday.transform(dataset['wday'])\n",
    "    dataset['image_code'] = le_image_code.transform(dataset['image_code'])\n",
    "    \n",
    "    print(\"Transform on test function completed.\")\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "def keras_test_transform(dataset):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    dataset['title_description']= (dataset['title']+\" \"+dataset['description']).astype(str)\n",
    "    del dataset['description'], dataset['title']\n",
    "    gc.collect()\n",
    "    \n",
    "    dataset['seq_title_description']= tokenizer.texts_to_sequences(dataset.title_description.str.lower())\n",
    "    print(\"Transform done for test\")\n",
    "    print(\"Time taken for Sequence Tokens is\"+str(time.time()-t1))\n",
    "    \n",
    "    del dataset['title_description']\n",
    "    gc.collect()\n",
    "\n",
    "    dataset['region'] = le_region.transform(dataset['region'])\n",
    "    dataset['city'] = le_city.transform(dataset['city'])\n",
    "    dataset['category_name'] = le_category_name.transform(dataset['category_name'])\n",
    "    dataset['parent_category_name'] = le_parent_category_name.transform(dataset['parent_category_name'])\n",
    "    dataset['param_1'] = le_param_1.transform(dataset['param_1'])\n",
    "    dataset['param123'] = le_param123.transform(dataset['param123'])\n",
    "    #dataset['day'] = le_day.transform(dataset['day'])\n",
    "    #dataset['week'] = le_week.transform(dataset['week'])\n",
    "    #dataset['wday'] = le_wday.transform(dataset['wday'])\n",
    "    dataset['image_code'] = le_image_code.transform(dataset['image_code'])\n",
    "    \n",
    "    dataset['price'] = np.log1p(dataset['price'])\n",
    "    dataset['item_seq_number'] = np.log(dataset['item_seq_number'])\n",
    "    dataset['avg_days_up_user'] = np.log1p(dataset['avg_days_up_user'])\n",
    "    dataset['avg_times_up_user'] = np.log1p(dataset['avg_times_up_user'])\n",
    "    dataset['n_user_items'] = np.log1p(dataset['n_user_items'])\n",
    "    \n",
    "    print(\"Transform on test function completed.\")\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'seq_title_description': pad_sequences(dataset.seq_title_description, maxlen=max_seq_title_description_length)\n",
    "        ,'region': np.array(dataset.region)\n",
    "        ,'city': np.array(dataset.city)\n",
    "        ,'category_name': np.array(dataset.category_name)\n",
    "        ,'parent_category_name': np.array(dataset.parent_category_name)\n",
    "        ,'param_1': np.array(dataset.param_1)\n",
    "        ,'param123': np.array(dataset.param123)\n",
    "        ,'image_code':np.array(dataset.image_code)\n",
    "        ,'avg_ad_days':np.array(dataset.avg_days_up_user )\n",
    "        ,'avg_ad_times':np.array(dataset.avg_times_up_user)\n",
    "        ,'n_user_items':np.array(dataset.n_user_items)\n",
    "        ,'price': np.array(dataset[[\"price\"]])\n",
    "        ,'item_seq_number': np.array(dataset[[\"item_seq_number\"]])\n",
    "    }\n",
    "    \n",
    "    print(\"Data ready for Vectorization\")\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "Start Tokenization.....\n",
      "Loading Test for Label Encoding on Train + Test\n",
      "Creating New Feature.....\n",
      "(2011862, 15)\n",
      "Start Label Encoding process....\n",
      "Fit on Train Function completed.\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is94.26853108406067\n",
      "Transform on test function completed.\n",
      "Tokenization done and TRAIN READY FOR Validation splitting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Train data - No Params, No Image data \n",
    "dtypes_train = {\n",
    "                'price': 'float32',\n",
    "                'deal probability': 'float32',\n",
    "                'item_seq_number': 'uint32'\n",
    "}\n",
    "\n",
    "# No user_id\n",
    "use_cols = ['item_id', 'user_id', 'image_top_1', 'region', 'city', 'parent_category_name', 'category_name', 'param_1', 'param_2', 'param_3', 'title', 'description', 'price', 'item_seq_number', 'activation_date', 'deal_probability']\n",
    "train = pd.read_csv(\"/home/g492652607/data/train.csv\", parse_dates=[\"activation_date\"], usecols = use_cols, dtype = dtypes_train)\n",
    "\n",
    "train_features = pd.read_csv('/home/g492652607/data/aggregated_features.csv')\n",
    "train = train.merge(train_features, on = ['user_id'], how = 'left')\n",
    "del train_features\n",
    "gc.collect()\n",
    "\n",
    "train['avg_days_up_user'] = train['avg_days_up_user'].fillna(0).astype('uint32')\n",
    "train['avg_times_up_user'] = train['avg_times_up_user'].fillna(0).astype('uint32')\n",
    "train['n_user_items'] = train['n_user_items'].fillna(0).astype('uint32')\n",
    "\n",
    "y_train = np.array(train['deal_probability'])\n",
    "\n",
    "del train['deal_probability']\n",
    "gc.collect()\n",
    "\n",
    "max_seq_title_description_length = 100\n",
    "max_words_title_description = 200000\n",
    "\n",
    "train = preprocess_dataset(train)\n",
    "train, tokenizer, le_region, le_city, le_category_name, le_parent_category_name, le_param_1, le_param123, le_image_code = keras_fit(train)\n",
    "train = keras_train_transform(train)\n",
    "print(\"Tokenization done and TRAIN READY FOR Validation splitting\")\n",
    "\n",
    "# Calculation of max values for Categorical fields \n",
    "\n",
    "max_region = np.max(train.region.max())+2\n",
    "max_city= np.max(train.city.max())+2\n",
    "max_category_name = np.max(train.category_name.max())+2\n",
    "max_parent_category_name = np.max(train.parent_category_name.max())+2\n",
    "max_param_1 = np.max(train.param_1.max())+2\n",
    "max_param123 = np.max(train.param123.max())+2\n",
    "#max_week = np.max(train.week.max())+2\n",
    "#max_day = np.max(train.day.max())+2\n",
    "#max_wday = np.max(train.wday.max())+2\n",
    "max_image_code = np.max(train.image_code.max())+2\n",
    "\n",
    "del train['item_id'], train['user_id']\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748126, 300)\n",
      "281646 466478 466478 281646\n",
      "(748126, 300)\n",
      " FAST TEXT DONE\n"
     ]
    }
   ],
   "source": [
    "# EMBEDDINGS COMBINATION \n",
    "# FASTTEXT\n",
    "\n",
    "EMBEDDING_DIM1 = 300\n",
    "EMBEDDING_FILE1 = '/home/g492652607/data/fasttest-common-crawl-russian/cc.ru.300.vec'\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index1 = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE1))\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)+2\n",
    "EMBEDDING_DIM1 = 300# this is from the pretrained vectors\n",
    "embedding_matrix1 = np.zeros((vocab_size, EMBEDDING_DIM1))\n",
    "print(embedding_matrix1.shape)\n",
    "# Creating Embedding matrix \n",
    "c = 0 \n",
    "c1 = 0 \n",
    "w_Y = []\n",
    "w_No = []\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embeddings_index1:\n",
    "        c +=1\n",
    "        embedding_vector = embeddings_index1[word]\n",
    "        w_Y.append(word)\n",
    "    else:\n",
    "        embedding_vector = None\n",
    "        w_No.append(word)\n",
    "        c1 +=1\n",
    "    if embedding_vector is not None:    \n",
    "        embedding_matrix1[i] = embedding_vector\n",
    "\n",
    "print(c,c1, len(w_No), len(w_Y))\n",
    "print(embedding_matrix1.shape)\n",
    "del embeddings_index1\n",
    "gc.collect()\n",
    "\n",
    "print(\" FAST TEXT DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_model():\n",
    "\n",
    "    #Inputs\n",
    "    seq_title_description = Input(shape=[100], name=\"seq_title_description\")\n",
    "    region = Input(shape=[1], name=\"region\")\n",
    "    city = Input(shape=[1], name=\"city\")\n",
    "    category_name = Input(shape=[1], name=\"category_name\")\n",
    "    parent_category_name = Input(shape=[1], name=\"parent_category_name\")\n",
    "    param_1 = Input(shape=[1], name=\"param_1\")\n",
    "    param123 = Input(shape=[1], name=\"param123\")\n",
    "    image_code = Input(shape=[1], name=\"image_code\")\n",
    "    price = Input(shape=[1], name=\"price\")\n",
    "    item_seq_number = Input(shape = [1], name = 'item_seq_number')\n",
    "    avg_ad_days = Input(shape=[1], name=\"avg_ad_days\")\n",
    "    avg_ad_times = Input(shape=[1], name=\"avg_ad_times\")\n",
    "    n_user_items = Input(shape=[1], name=\"n_user_items\")\n",
    "    \n",
    "    #Embeddings layers\n",
    "\n",
    "    emb_seq_title_description = Embedding(vocab_size, EMBEDDING_DIM1, weights = [embedding_matrix1], trainable = False)(seq_title_description)\n",
    "    emb_region = Embedding(vocab_size, 10)(region)\n",
    "    emb_city = Embedding(vocab_size, 10)(city)\n",
    "    emb_category_name = Embedding(vocab_size, 10)(category_name)\n",
    "    emb_parent_category_name = Embedding(vocab_size, 10)(parent_category_name)\n",
    "    emb_param_1 = Embedding(vocab_size, 10)(param_1)\n",
    "    emb_param123 = Embedding(vocab_size, 10)(param123)\n",
    "    emb_image_code = Embedding(vocab_size, 10)(image_code)\n",
    "\n",
    "    rnn_layer1 = GRU(50) (emb_seq_title_description)\n",
    "    \n",
    "    #main layer\n",
    "    main_l = concatenate([\n",
    "          rnn_layer1\n",
    "        , Flatten() (emb_region)\n",
    "        , Flatten() (emb_city)\n",
    "        , Flatten() (emb_category_name)\n",
    "        , Flatten() (emb_parent_category_name)\n",
    "        , Flatten() (emb_param_1)\n",
    "        , Flatten() (emb_param123)\n",
    "        , Flatten() (emb_image_code)\n",
    "        , avg_ad_days\n",
    "        , avg_ad_times\n",
    "        , n_user_items\n",
    "        , price\n",
    "        , item_seq_number\n",
    "    ])\n",
    "    \n",
    "    main_l = Dropout(0.1)(Dense(512,activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(64,activation='relu') (main_l))\n",
    "    \n",
    "    #output\n",
    "    output = Dense(1,activation=\"sigmoid\") (main_l)\n",
    "    \n",
    "    #model\n",
    "    model = Model([seq_title_description, region, city, category_name, parent_category_name, param_1, param123, price, item_seq_number, image_code, avg_ad_days, avg_ad_times, n_user_items], output)\n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss= root_mean_squared_error,\n",
    "                  metrics = [root_mean_squared_error])\n",
    "    return model\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "\n",
    "    Rsum = np.sum((y - y_pred)**2)\n",
    "    n = y.shape[0]\n",
    "    RMSE = np.sqrt(Rsum/n)\n",
    "    return RMSE \n",
    "\n",
    "def eval_model(model, X_test1):\n",
    "    val_preds = model.predict(X_test1)\n",
    "    y_pred = val_preds[:, 0]\n",
    "    \n",
    "    y_true = np.array(y_test1)\n",
    "    \n",
    "    yt = pd.DataFrame(y_true)\n",
    "    yp = pd.DataFrame(y_pred)\n",
    "    \n",
    "    print(yt.isnull().any())\n",
    "    print(yp.isnull().any())\n",
    "    \n",
    "    v_rmse = rmse(y_true, y_pred)\n",
    "    print(\" RMSE for VALIDATION SET: \"+str(v_rmse))\n",
    "    return v_rmse\n",
    "\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(model):\n",
    "    import time\n",
    "    t1 = time.time()\n",
    "    def load_test():\n",
    "        for df in pd.read_csv('/home/g492652607/data/test.csv', chunksize= 250000):\n",
    "            yield df\n",
    "\n",
    "    item_ids = np.array([], dtype=np.int32)\n",
    "    preds= np.array([], dtype=np.float32)\n",
    "\n",
    "    i = 0 \n",
    "    \n",
    "    for df in load_test():\n",
    "    \n",
    "        i +=1\n",
    "        print(df.dtypes)\n",
    "        item_id = df['item_id']\n",
    "        print(\" Chunk number is \"+str(i))\n",
    "    \n",
    "        test = preprocess_dataset(df)\n",
    "    \n",
    "        train_features = pd.read_csv('/home/g492652607/data/aggregated_features.csv')\n",
    "        test = test.merge(train_features, on = ['user_id'], how = 'left')\n",
    "        del train_features\n",
    "        gc.collect()\n",
    "    \n",
    "        print(test.dtypes)\n",
    "        \n",
    "        test['avg_days_up_user'] = test['avg_days_up_user'].fillna(0).astype('uint32')\n",
    "        test['avg_times_up_user'] = test['avg_times_up_user'].fillna(0).astype('uint32')\n",
    "        test['n_user_items'] = test['n_user_items'].fillna(0).astype('uint32')\n",
    "        test = keras_test_transform(test)\n",
    "        del df\n",
    "        gc.collect()\n",
    "    \n",
    "        print(test.dtypes)\n",
    "    \n",
    "        X_test = get_keras_data(test)\n",
    "        del test \n",
    "        gc.collect()\n",
    "    \n",
    "        Batch_Size = 512*3\n",
    "        preds1 = modelRNN.predict(X_test, batch_size = Batch_Size, verbose = 1)\n",
    "        print(preds1.shape)\n",
    "        del X_test\n",
    "        gc.collect()\n",
    "        print(\"RNN Prediction is done\")\n",
    "\n",
    "        preds1 = preds1.reshape(-1,1)\n",
    "        #print(predsl.shape)\n",
    "        preds1 = np.clip(preds1, 0, 1)\n",
    "        print(preds1.shape)\n",
    "        item_ids = np.append(item_ids, item_id)\n",
    "        print(item_ids.shape)\n",
    "        preds = np.append(preds, preds1)\n",
    "        print(preds.shape)\n",
    "        \n",
    "    print(\"All chunks done\")\n",
    "    t2 = time.time()\n",
    "    print(\"Total time for Parallel Batch Prediction is \"+str(t2-t1))\n",
    "    return preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = np.array(train.values)\n",
    "del train\n",
    "gc.collect()\n",
    "\n",
    "def get_data_frame(dataset):\n",
    "    \n",
    "    DF = pd.DataFrame()\n",
    "    \n",
    "    DF['avg_days_up_user'] = np.array(dataset[:,0])\n",
    "    DF['avg_times_up_user'] = np.array(dataset[:,1])\n",
    "    DF['category_name'] = np.array(dataset[:,2])\n",
    "    DF['city'] = np.array(dataset[:,3])\n",
    "    DF['image_code'] = np.array(dataset[:,4])\n",
    "    DF['item_seq_number'] = np.array(dataset[:,5])\n",
    "    DF['n_user_items'] = np.array(dataset[:,6])\n",
    "    DF['param123'] = np.array(dataset[:,7])\n",
    "    DF['param_1'] = np.array(dataset[:,8])\n",
    "    DF['parent_category_name'] = np.array(dataset[:,9])\n",
    "    DF['price'] = np.array(dataset[:,10])\n",
    "    DF['region'] = np.array(dataset[:,11])\n",
    "    DF['seq_title_description'] = np.array(dataset[:,12])\n",
    "    \n",
    "    return DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Folds..1\n",
      "(1202739, 13) (300685, 13)\n",
      "(1202739,) (300685,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1202739, 13)\n",
      "<class 'numpy.ndarray'>\n",
      "Data ready for Vectorization\n",
      "Data ready for Vectorization\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1287s 1ms/step - loss: 0.2307 - root_mean_squared_error: 0.2307 - val_loss: 0.2265 - val_root_mean_squared_error: 0.2265\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1090s 907us/step - loss: 0.2224 - root_mean_squared_error: 0.2224 - val_loss: 0.2225 - val_root_mean_squared_error: 0.2225\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1039s 864us/step - loss: 0.2201 - root_mean_squared_error: 0.2201 - val_loss: 0.2210 - val_root_mean_squared_error: 0.2210\n",
      "0    False\n",
      "dtype: bool\n",
      "0    False\n",
      "dtype: bool\n",
      " RMSE for VALIDATION SET: 0.22098157893767242\n",
      "300685/300685 [==============================] - 226s 753us/step\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 1\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is17.309755563735962\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 118s 473us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(250000,)\n",
      "(250000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 2\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is17.748581886291504\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 118s 473us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(500000,)\n",
      "(500000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 3\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is1.760540246963501\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "8438/8438 [==============================] - 4s 470us/step\n",
      "(8438, 1)\n",
      "RNN Prediction is done\n",
      "(8438, 1)\n",
      "(508438,)\n",
      "(508438,)\n",
      "All chunks done\n",
      "Total time for Parallel Batch Prediction is 346.9041919708252\n",
      "Predictions done for Fold 0\n",
      "(508438,)\n",
      "Number of folds completed....1\n",
      "[0.34490076 0.06381506 0.22369622 0.08253099 0.2816258  0.145817\n",
      " 0.03326111 0.0091517  0.03377955 0.04260118]\n",
      "Number of Folds..1\n",
      "(1202739, 13) (300685, 13)\n",
      "(1202739,) (300685,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1202739, 13)\n",
      "<class 'numpy.ndarray'>\n",
      "Data ready for Vectorization\n",
      "Data ready for Vectorization\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1254s 1ms/step - loss: 0.2309 - root_mean_squared_error: 0.2309 - val_loss: 0.2273 - val_root_mean_squared_error: 0.2273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1086s 903us/step - loss: 0.2230 - root_mean_squared_error: 0.2230 - val_loss: 0.2246 - val_root_mean_squared_error: 0.2246\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1045s 869us/step - loss: 0.2211 - root_mean_squared_error: 0.2211 - val_loss: 0.2218 - val_root_mean_squared_error: 0.2218\n",
      "0    False\n",
      "dtype: bool\n",
      "0    False\n",
      "dtype: bool\n",
      " RMSE for VALIDATION SET: 0.22176893225645397\n",
      "300685/300685 [==============================] - 216s 718us/step\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 1\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is17.238439321517944\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 119s 475us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(250000,)\n",
      "(250000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 2\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is18.480147123336792\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 118s 472us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(500000,)\n",
      "(500000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 3\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is1.880293607711792\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "8438/8438 [==============================] - 4s 470us/step\n",
      "(8438, 1)\n",
      "RNN Prediction is done\n",
      "(8438, 1)\n",
      "(508438,)\n",
      "(508438,)\n",
      "All chunks done\n",
      "Total time for Parallel Batch Prediction is 349.0435652732849\n",
      "Predictions done for Fold 0\n",
      "(508438,)\n",
      "Number of folds completed....2\n",
      "[0.34490076 0.06381506 0.22369622 0.08253099 0.2816258  0.145817\n",
      " 0.03326111 0.0091517  0.03377955 0.04260118]\n",
      "Number of Folds..1\n",
      "(1202739, 13) (300685, 13)\n",
      "(1202739,) (300685,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1202739, 13)\n",
      "<class 'numpy.ndarray'>\n",
      "Data ready for Vectorization\n",
      "Data ready for Vectorization\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1237s 1ms/step - loss: 0.2301 - root_mean_squared_error: 0.2301 - val_loss: 0.2254 - val_root_mean_squared_error: 0.2254\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1090s 907us/step - loss: 0.2220 - root_mean_squared_error: 0.2220 - val_loss: 0.2221 - val_root_mean_squared_error: 0.2221\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202739/1202739 [==============================] - 1050s 873us/step - loss: 0.2205 - root_mean_squared_error: 0.2205 - val_loss: 0.2211 - val_root_mean_squared_error: 0.2211\n",
      "0    False\n",
      "dtype: bool\n",
      "0    False\n",
      "dtype: bool\n",
      " RMSE for VALIDATION SET: 0.22115237657457035\n",
      "300685/300685 [==============================] - 219s 727us/step\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 1\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is17.970113277435303\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 120s 479us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(250000,)\n",
      "(250000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 2\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is18.387538194656372\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 120s 479us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(500000,)\n",
      "(500000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 3\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is1.846156120300293\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "8438/8438 [==============================] - 4s 473us/step\n",
      "(8438, 1)\n",
      "RNN Prediction is done\n",
      "(8438, 1)\n",
      "(508438,)\n",
      "(508438,)\n",
      "All chunks done\n",
      "Total time for Parallel Batch Prediction is 352.30006098747253\n",
      "Predictions done for Fold 0\n",
      "(508438,)\n",
      "Number of folds completed....3\n",
      "[0.34490076 0.06381506 0.22369622 0.08253099 0.2816258  0.145817\n",
      " 0.03326111 0.0091517  0.03377955 0.04260118]\n",
      "Number of Folds..1\n",
      "(1202739, 13) (300685, 13)\n",
      "(1202739,) (300685,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1202739, 13)\n",
      "<class 'numpy.ndarray'>\n",
      "Data ready for Vectorization\n",
      "Data ready for Vectorization\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1278s 1ms/step - loss: 0.2300 - root_mean_squared_error: 0.2300 - val_loss: 0.2249 - val_root_mean_squared_error: 0.2249\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1243s 1ms/step - loss: 0.2224 - root_mean_squared_error: 0.2224 - val_loss: 0.2242 - val_root_mean_squared_error: 0.2242\n",
      "Train on 1202739 samples, validate on 300685 samples\n",
      "Epoch 1/1\n",
      "1202739/1202739 [==============================] - 1141s 949us/step - loss: 0.2205 - root_mean_squared_error: 0.2205 - val_loss: 0.2213 - val_root_mean_squared_error: 0.2213\n",
      "0    False\n",
      "dtype: bool\n",
      "0    False\n",
      "dtype: bool\n",
      " RMSE for VALIDATION SET: 0.22130809115414196\n",
      "300685/300685 [==============================] - 255s 849us/step\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 1\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is19.881792783737183\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 129s 514us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(250000,)\n",
      "(250000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 2\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is19.932278871536255\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 129s 515us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(500000,)\n",
      "(500000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 3\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is2.157992362976074\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "8438/8438 [==============================] - 4s 517us/step\n",
      "(8438, 1)\n",
      "RNN Prediction is done\n",
      "(8438, 1)\n",
      "(508438,)\n",
      "(508438,)\n",
      "All chunks done\n",
      "Total time for Parallel Batch Prediction is 384.1396496295929\n",
      "Predictions done for Fold 0\n",
      "(508438,)\n",
      "Number of folds completed....4\n",
      "[0.34490076 0.06381506 0.22369622 0.08253099 0.2816258  0.145817\n",
      " 0.03326111 0.0091517  0.03377955 0.04260118]\n",
      "Number of Folds..1\n",
      "(1202740, 13) (300684, 13)\n",
      "(1202740,) (300684,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1202740, 13)\n",
      "<class 'numpy.ndarray'>\n",
      "Data ready for Vectorization\n",
      "Data ready for Vectorization\n",
      "Train on 1202740 samples, validate on 300684 samples\n",
      "Epoch 1/1\n",
      "1202740/1202740 [==============================] - 1342s 1ms/step - loss: 0.2300 - root_mean_squared_error: 0.2300 - val_loss: 0.2278 - val_root_mean_squared_error: 0.2278\n",
      "Train on 1202740 samples, validate on 300684 samples\n",
      "Epoch 1/1\n",
      "1202740/1202740 [==============================] - 1179s 980us/step - loss: 0.2224 - root_mean_squared_error: 0.2224 - val_loss: 0.2248 - val_root_mean_squared_error: 0.2248\n",
      "Train on 1202740 samples, validate on 300684 samples\n",
      "Epoch 1/1\n",
      "1202740/1202740 [==============================] - 1117s 928us/step - loss: 0.2205 - root_mean_squared_error: 0.2205 - val_loss: 0.2221 - val_root_mean_squared_error: 0.2221\n",
      "0    False\n",
      "dtype: bool\n",
      "0    False\n",
      "dtype: bool\n",
      " RMSE for VALIDATION SET: 0.22206540225831403\n",
      "300684/300684 [==============================] - 263s 875us/step\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 1\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform done for test\n",
      "Time taken for Sequence Tokens is19.437832355499268\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 130s 518us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(250000,)\n",
      "(250000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 2\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is19.777239561080933\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "250000/250000 [==============================] - 129s 516us/step\n",
      "(250000, 1)\n",
      "RNN Prediction is done\n",
      "(250000, 1)\n",
      "(500000,)\n",
      "(500000,)\n",
      "item_id                  object\n",
      "user_id                  object\n",
      "region                   object\n",
      "city                     object\n",
      "parent_category_name     object\n",
      "category_name            object\n",
      "param_1                  object\n",
      "param_2                  object\n",
      "param_3                  object\n",
      "title                    object\n",
      "description              object\n",
      "price                   float64\n",
      "item_seq_number           int64\n",
      "activation_date          object\n",
      "user_type                object\n",
      "image                    object\n",
      "image_top_1             float64\n",
      "dtype: object\n",
      " Chunk number is 3\n",
      "Filling Missing Values.....\n",
      "Casting data types to type Category.......\n",
      "Creating New Feature.....\n",
      "PreProcessing Function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                  category\n",
      "city                    category\n",
      "parent_category_name    category\n",
      "category_name           category\n",
      "param_1                   object\n",
      "title                     object\n",
      "description               object\n",
      "price                    float32\n",
      "item_seq_number            int64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                object\n",
      "param123                  object\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items               int64\n",
      "dtype: object\n",
      "Transform done for test\n",
      "Time taken for Sequence Tokens is2.153532028198242\n",
      "Transform on test function completed.\n",
      "item_id                   object\n",
      "user_id                   object\n",
      "region                     int64\n",
      "city                       int64\n",
      "parent_category_name       int64\n",
      "category_name              int64\n",
      "param_1                    int64\n",
      "price                    float32\n",
      "item_seq_number          float64\n",
      "user_type                 object\n",
      "image                     object\n",
      "image_code                 int64\n",
      "param123                   int64\n",
      "avg_days_up_user         float64\n",
      "avg_times_up_user        float64\n",
      "n_user_items             float64\n",
      "seq_title_description     object\n",
      "dtype: object\n",
      "Data ready for Vectorization\n",
      "8438/8438 [==============================] - 4s 523us/step\n",
      "(8438, 1)\n",
      "RNN Prediction is done\n",
      "(8438, 1)\n",
      "(508438,)\n",
      "(508438,)\n",
      "All chunks done\n",
      "Total time for Parallel Batch Prediction is 387.7185196876526\n",
      "Predictions done for Fold 0\n",
      "(508438,)\n",
      "Number of folds completed....5\n",
      "[0.34490076 0.06381506 0.22369622 0.08253099 0.2816258  0.145817\n",
      " 0.03326111 0.0091517  0.03377955 0.04260118]\n",
      "All Folds completed1\n",
      "RNN FOLD MODEL Done\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9d7129ea5486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RNN FOLD MODEL Done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0moof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rnn_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'oof_rnn.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import time \n",
    "skf = KFold(n_splits = 5)\n",
    "Kfold_preds_final = []\n",
    "k = 0\n",
    "RMSE = []\n",
    "\n",
    "ntrain=train1.shape[0]\n",
    "oof_train = np.zeros((ntrain,))\n",
    "\n",
    "for train_idx, test_idx in skf.split(train1, y_train):\n",
    "    \n",
    "    print(\"Number of Folds..\"+str(k+1))\n",
    "    \n",
    "    # Initialize a new Model for Current FOLD \n",
    "    epochs = 1\n",
    "    batch_size = 512 * 3\n",
    "    steps = (int(train1.shape[0]/batch_size))*epochs\n",
    "    lr_init, lr_fin = 0.009, 0.0045\n",
    "    lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "    modelRNN = RNN_model()\n",
    "    K.set_value(modelRNN.optimizer.lr, lr_init)\n",
    "    K.set_value(modelRNN.optimizer.decay, lr_decay)\n",
    "\n",
    "    #K Fold Split \n",
    "    \n",
    "    X_train1, X_test1 = train1[train_idx], train1[test_idx]\n",
    "    print(X_train1.shape, X_test1.shape)\n",
    "    y_train1, y_test1 = y_train[train_idx], y_train[test_idx]\n",
    "    print(y_train1.shape, y_test1.shape)\n",
    "    n=X_test1.shape[0]\n",
    "    gc.collect()\n",
    "    \n",
    "    print(type(X_train1))\n",
    "    print(X_train1.shape)\n",
    "    print(type(X_train1[:,12]))\n",
    "    \n",
    "    X_train_final = get_data_frame(X_train1)\n",
    "    X_test_final = get_data_frame(X_test1)\n",
    "    \n",
    "    del X_train1, X_test1\n",
    "    gc.collect()\n",
    "    \n",
    "    X_train_f = get_keras_data(X_train_final)\n",
    "    X_test_f = get_keras_data(X_test_final)\n",
    "    \n",
    "    del X_train_final, X_test_final\n",
    "    gc.collect()\n",
    "\n",
    "    # Fit the NN Model \n",
    "    for i in range(3):\n",
    "        hist = modelRNN.fit(X_train_f, y_train1, batch_size=batch_size+(batch_size*(2*i)), epochs=epochs, validation_data=(X_test_f, y_test1), verbose=1)\n",
    "\n",
    "    del X_train_f\n",
    "    gc.collect()\n",
    "\n",
    "    # Print RMSE for Validation set for Kth Fold \n",
    "    v_rmse = eval_model(modelRNN, X_test_f)\n",
    "    RMSE.append(v_rmse)\n",
    "    \n",
    "#    del X_test_f\n",
    "    del y_train1, y_test1\n",
    "    gc.collect()\n",
    "    \n",
    "    predict0 = modelRNN.predict(X_test_f, verbose=1)\n",
    "    oof_train[test_idx] = predict0.reshape(n,)\n",
    "    \n",
    "    # Predict test set for Kth Fold \n",
    "    preds = predictions(modelRNN)\n",
    "    del modelRNN \n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Predictions done for Fold \"+str(k))\n",
    "    print(preds.shape)\n",
    "    Kfold_preds_final.append(preds)\n",
    "    del preds\n",
    "    gc.collect()\n",
    "    print(\"Number of folds completed....\"+str(len(Kfold_preds_final)))\n",
    "    print(Kfold_preds_final[k][0:10])\n",
    "\n",
    "print(\"All Folds completed\"+str(k+1))   \n",
    "print(\"RNN FOLD MODEL Done\")\n",
    "\n",
    "oof = pd.Dataframe(oof_train, columns=['rnn_pred'])\n",
    "oof.to_csv('oof_rnn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = pd.DataFrame(oof_train, columns=['rnn_pred'])\n",
    "oof.to_csv('oof_rnn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final1 = np.average(Kfold_preds_final, axis =0) # Average of all K Folds\n",
    "print(pred_final1.shape)\n",
    "\n",
    "min_value = min(RMSE)\n",
    "RMSE_idx = RMSE.index(min_value)\n",
    "print(RMSE_idx)\n",
    "pred_final2 = Kfold_preds_final[RMSE_idx]\n",
    "print(pred_final2.shape)\n",
    "\n",
    "#del Kfold_preds_final, train1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = ['item_id']\n",
    "test = pd.read_csv('/home/g492652607/data/test.csv', usecols = test_cols)\n",
    "\n",
    "# using Average of KFOLD preds \n",
    "\n",
    "submission1 = pd.DataFrame( columns = ['item_id', 'deal_probability'])\n",
    "\n",
    "submission1['item_id'] = test['item_id']\n",
    "submission1['deal_probability'] = pred_final1\n",
    "\n",
    "print(\"Check Submission NOW!!!!!!!!@\")\n",
    "submission1.to_csv(\"Avito_Shanth_RNN_AVERAGE.csv\", index=False)\n",
    "\n",
    "# Using KFOLD preds with Minimum value \n",
    "submission2 = pd.DataFrame( columns = ['item_id', 'deal_probability'])\n",
    "\n",
    "submission2['item_id'] = test['item_id']\n",
    "submission2['deal_probability'] = pred_final2\n",
    "\n",
    "print(\"Check Submission NOW!!!!!!!!@\")\n",
    "submission2.to_csv(\"Avito_Shanth_RNN_MIN.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
